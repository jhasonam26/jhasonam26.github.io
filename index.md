<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-148953677-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-148953677-1');
</script>

## Welcome to Mohna Chakraborty's homepage
<span style="font-size:1.35em;">
I am a third year Ph.D. student at the Department of Computer Science at Iowa State University. I am working as a Research Assistant at the <a href="https://sites.google.com/iastate.edu/qili/publications"> Data Mining and Knowledge Lab</a>. My supervisor is <a href="https://sites.google.com/iastate.edu/qili/">Dr. Qi Li</a>. Also, I have worked as a PhD intern at Epsilon in Decision Science team. My area of interest is Review Analysis, True label inference, Data Mining, Natural Language Processing, Machine Learning.</span>


## Publications
<span style="font-size:1.35em;">
<b><font color="red">2022</font></b><br>
<b>Mohna Chakraborty</b> , Adithya Kulkarni, and Qi Li.
Open-Domain Aspect-Opinion Co-Mining with Double-Layer Span Extraction,
<b>SIGKDD, 2022</b> [<a 
href="https://doi.org/10.1145/3534678.3539386"><span style='color:#954F72'>paper</span></a>]
<br><br> 

<span style="font-size:1.35em;">
<b><font color="red">2021</font></b><br>
Richard D Jiles, <b>Mohna Chakraborty</b>.
[Re] Domain Generalization using Causal Matching,
<b>ML Reproducibility Challenge, 2021</b>: [<a 
href="https://openreview.net/forum?id=r43elaGmhCY"><span style='color:#954F72'>paper</span></a>]
<br><br>
Abhishek Kumar Mishra, <b>Mohna Chakraborty</b>. Does local pruning offer task-specific models to learn effectively?,
<b>Proceedings of the Student Research Workshop Associated with RANLP, 2021</b>: [<a
href="https://aclanthology.org/2021.ranlp-srw.17"><span style='color:#954F72'>paper</span></a>]
<br><br>
<b>Mohna Chakraborty</b>. Does reusing pre-trained NLP model propagate bugs?,
<b>ESEC/FSE, 2021</b>: [<a
href="https://doi.org/10.1145/3468264.3473494"><span style='color:#954F72'>paper</span></a>]
<br><br>


## Recent News!
<span style="font-size:1.35em;">
<b>Sep '22</b>: Selected to represent Iowa State University for the prestigious and competitive Grace Hopper Celebration.<br>
<br> <b>Aug '22</b>: Awarded Student Travel Award for SIGKDD 2022.<br>
<br> <b>July '22</b>: I served as Review member at HCOMP 2022.<br>
<br> <b>July '22</b>: I served as Review member at EMNLP 2022.<br>
<br> <b>May '22</b>: Our paper on "Open-Domain Aspect-Opinion Co-Mining with Double-Layer Span Extraction" has been accepted at SIGKDD 2022.<br>
<br> <b>May '22</b>: Joined Epsilon as a PhD intern.<br>
<br> <b>April '22</b>: Defended my research proficiency on Weakly Supervised Review Analysis Based on Task Correlation.<br>
<br> <b>March '22</b>: Awarded 1st position for 6th Annual Research Competition at Iowa State University.<br>
<br> <b>March '22</b>: Our paper on "[Re] Domain Generalization using Causal Matching" has been accepted at ML Reproducibility Challenge 2021 (Fall Edition).<br>
<br> <b>Dec '21</b>: Served as Review member at PAKDD 2021.<br>
<br> <b>Sep '21</b>: Our paper on "Does local pruning offer task-specific models to learn effectively?" has been accepted at RANLP 2021.<br>
<br> <b>Aug '21</b>: Present SRC paper "Does reusing pre-trained NLP model propagate bugs?", ESEC/FSE, 2021.<br>
<br> <b>June '21</b>: Our paper on "Does reusing pre-trained NLP model propagate bugs?" has been accepted at ESEC/FSE, SRC 2021.<br>
<br> <b>May '21</b>: Joined Epsilon as a PhD intern.<br>
<br> <b>Aug '20</b>: Joined Ph.D. program at the Department of Computer Science at Iowa State University.<br></span>


